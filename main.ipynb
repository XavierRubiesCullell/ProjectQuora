{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.simplefilter(action='ignore', category=FutureWarning)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Files\n",
    "import input_net\n",
    "import utils\n",
    "\n",
    "# Packages\n",
    "from os import path\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "\n",
    "from transformers import AlbertConfig, AlbertForSequenceClassification, AlbertTokenizer\n",
    "from transformers import BartConfig, BartForSequenceClassification, BartTokenizer\n",
    "from transformers import BertConfig, BertForSequenceClassification, BertTokenizer\n",
    "from transformers import CamembertConfig, CamembertForSequenceClassification, CamembertTokenizer\n",
    "from transformers import DistilBertConfig, DistilBertForSequenceClassification, DistilBertTokenizer\n",
    "from transformers import FlaubertConfig, FlaubertForSequenceClassification, FlaubertTokenizer\n",
    "from transformers import RobertaConfig, RobertaForSequenceClassification, RobertaTokenizer\n",
    "from transformers import XLMConfig, XLMForSequenceClassification, XLMTokenizer\n",
    "from transformers import XLMRobertaConfig, XLMRobertaForSequenceClassification, XLMRobertaTokenizer\n",
    "from transformers import XLNetConfig, XLNetForSequenceClassification, XLNetTokenizer\n",
    "\n",
    "# Optimizer -> busca info de com s'utilitza\n",
    "from transformers import AdamW, get_linear_schedule_with_warmup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "TRAIN = \"data/train.csv\"\n",
    "TEST = \"data/test.csv\"\n",
    "INPUT_NET = 'data/input.csv'\n",
    "\n",
    "tokenizer = BertTokenizer.from_pretrained('bert-base-uncased', do_lower_case=True)\n",
    "max_len = 70\n",
    "\n",
    "if not path.exists(INPUT_NET):\n",
    "    df = input_net.create_input(TRAIN, INPUT_NET, tokenizer, max_len))\n",
    "else:\n",
    "    df = pd.read_csv(INPUT_NET)\n",
    "\n",
    "tokens_tensor, segments_tensor, attention_tensor, targets_tensor = utils.ToTensor(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "MODEL_CLASSES = {\n",
    "    'albert': (AlbertConfig, AlbertForSequenceClassification, AlbertTokenizer),\n",
    "    'bart': (BartConfig, BartForSequenceClassification, BartTokenizer),\n",
    "    'bert': (BertConfig, BertForSequenceClassification, BertTokenizer),\n",
    "    'camembert': (CamembertConfig, CamembertForSequenceClassification, CamembertTokenizer),\n",
    "    'distilbert': (DistilBertConfig, DistilBertForSequenceClassification, DistilBertTokenizer),\n",
    "    'flaubert': (FlaubertConfig, FlaubertForSequenceClassification, FlaubertTokenizer),\n",
    "    'roberta': (RobertaConfig, RobertaForSequenceClassification, RobertaTokenizer),\n",
    "    'xlm': (XLMConfig, XLMForSequenceClassification, XLMTokenizer),\n",
    "    'xlm roberta': (XLMRobertaConfig, XLMRobertaForSequenceClassification, XLMRobertaTokenizer),\n",
    "    'xlnet': (XLNetConfig, XLNetForSequenceClassification, XLNetTokenizer)\n",
    "}\n",
    "\n",
    "config_class, model_class, tokenizer_class = MODEL_CLASSES[args['model_type']]\n",
    "\n",
    "# Mirar aixo:: AutoModelForSequenceClassification.from_pretrained(pretrained_model_name_or_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "args = {\n",
    "    'model_type': 'xlm',\n",
    "    'model_name': 'bert-base-cased',\n",
    "    'do_train': True,\n",
    "    'do_eval': True,\n",
    "    'max_seq_length': 70,\n",
    "    'batch_size': 16, \n",
    "\n",
    "    'num_train_epochs': 4,\n",
    "    'weight_decay': 0,\n",
    "    'learning_rate': 4e-5,\n",
    "    'adam_epsilon': 1e-8,\n",
    "    'warmup_steps': 0,\n",
    "    'max_grad_norm': 1.0,\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "tokenizer = tokenizer_class.from_pretrained(args['model_name'])\n",
    "\n",
    "model = model_class.from_pretrained(args['model_name'])\n",
    "\n",
    "no_decay = ['bias', 'LayerNorm.weight']\n",
    "optimizer_grouped_parameters = [\n",
    "        {'params': [p for n, p in model.named_parameters() if not any(nd in n for nd in no_decay)], 'weight_decay': args['weight_decay']},\n",
    "        {'params': [p for n, p in model.named_parameters() if any(nd in n for nd in no_decay)], 'weight_decay': 0.0}\n",
    "        ]\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = BertForSequenceClassification.from_pretrained(\"bert-base-uncased\", num_labels=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "Predictions = model(input_ids=tokens_tensor[:5],token_type_ids=segments_tensor[:5],attention_mask=attention_tensor[:5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "tensor([[0.6671, 0.3329],\n        [0.6624, 0.3376],\n        [0.6661, 0.3339],\n        [0.6886, 0.3114],\n        [0.6588, 0.3412]], grad_fn=<SoftmaxBackward>)"
     },
     "metadata": {},
     "execution_count": 24
    }
   ],
   "source": [
    "F.softmax(model(input_ids=tokens_tensor[:5],token_type_ids=segments_tensor[:5],attention_mask=attention_tensor[:5])[0], dim=1)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.6.9 64-bit",
   "language": "python",
   "name": "python36964bit3f9703cefae54e4a8e8d03694f9a0867"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "3.6.9-final"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}